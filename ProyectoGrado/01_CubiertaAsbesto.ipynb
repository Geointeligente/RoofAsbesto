{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1opaKypKCwV95x2NLgbbQjzodaB-WkMAm",
      "authorship_tag": "ABX9TyNeRiPa/Too9cNqY8JC4/x3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geointeligente/RoofAsbesto/blob/main/ProyectoGrado/01_CubiertaAsbesto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 1: Montar Google Drive**"
      ],
      "metadata": {
        "id": "aVItIHamvZkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQYOarOdvZ9I",
        "outputId": "6190b7dd-e8d3-46f9-99a6-b79bee84bcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 2: Definir rutas de los archivos en Google Drive**"
      ],
      "metadata": {
        "id": "ZQcuB16Tvhdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas de los archivos en Google Drive\n",
        "drive_paths = {\n",
        "    'yaml': '/content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/techos.yaml',\n",
        "    'train': '/content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/train.7z',\n",
        "    'valid': '/content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/valid.7z',\n",
        "    'test': '/content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/test.7z'\n",
        "}\n",
        "\n",
        "# Rutas locales donde se guardar√°n los archivos en Google Colab\n",
        "local_paths = {\n",
        "    'yaml': '/content/prueba/techos.yaml',\n",
        "    'train': '/content/prueba/train.7z',\n",
        "    'valid': '/content/prueba/valid.7z',\n",
        "    'test': '/content/prueba/test.7z'\n",
        "}"
      ],
      "metadata": {
        "id": "BKX942FDvjAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 3: Crear la carpeta prueba y copiar los archivos**"
      ],
      "metadata": {
        "id": "2-Sy40KKwJiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Crear la carpeta prueba\n",
        "os.makedirs('/content/prueba', exist_ok=True)\n",
        "\n",
        "# Copiar los archivos desde Google Drive a Google Colab\n",
        "for key in drive_paths.keys():\n",
        "    shutil.copy(drive_paths[key], local_paths[key])\n",
        "    print(f\"Copiado: {drive_paths[key]} -> {local_paths[key]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdLgsIgHwM_2",
        "outputId": "12b6b837-524e-47b5-c16b-187880717789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copiado: /content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/techos.yaml -> /content/prueba/techos.yaml\n",
            "Copiado: /content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/train.7z -> /content/prueba/train.7z\n",
            "Copiado: /content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/valid.7z -> /content/prueba/valid.7z\n",
            "Copiado: /content/drive/MyDrive/My Drive/MODELOTECHOASBESTO/test.7z -> /content/prueba/test.7z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "siWQX0h6wRuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 4: Descomprimir los archivos .7z **texto en negrita**\n",
        "Ahora, descomprimimos los archivos .7z dentro de la carpeta /content/prueba.**"
      ],
      "metadata": {
        "id": "LcLvV705wUve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import py7zr\n",
        "\n",
        "# Funci√≥n para descomprimir archivos .7z\n",
        "def extract_7z(file_path, extract_path):\n",
        "    with py7zr.SevenZipFile(file_path, mode='r') as z:\n",
        "        z.extractall(path=extract_path)\n",
        "\n",
        "# Descomprimir los archivos en la carpeta prueba\n",
        "extract_7z(local_paths['train'], '/content/prueba/train')\n",
        "extract_7z(local_paths['valid'], '/content/prueba/valid')\n",
        "extract_7z(local_paths['test'], '/content/prueba/test')\n",
        "\n",
        "print(\"Archivos descomprimidos exitosamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV5Zl-0QwSC-",
        "outputId": "bdefcddd-ca56-4bdf-a1b7-2be24c06035b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos descomprimidos exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 5: Verificar la estructura de carpetas\n",
        "Finalmente, verificamos que los archivos se hayan organizado correctamente.**"
      ],
      "metadata": {
        "id": "G6rpWlyZwcKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la estructura de carpetas\n",
        "!ls /content/prueba\n",
        "!ls /content/prueba/train\n",
        "!ls /content/prueba/valid\n",
        "!ls /content/prueba/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BNCupYoHwd2O",
        "outputId": "247bef15-6149-4ca6-c7d1-44fa472cd5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "techos.yaml  test  test.7z  train  train.7z  valid  valid.7z\n",
            "train\n",
            "valid\n",
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 6:Visualizar el contenido del archivo yaml**"
      ],
      "metadata": {
        "id": "lgAT2JBZwgu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZVsfj5_xQFE",
        "outputId": "4c66f0ea-fd7e-4b29-bed0-086b30c83142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cn7przCcxPRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo techos.yaml\n",
        "yaml_file_path = '/content/prueba/techos.yaml'\n",
        "\n",
        "# Leer y mostrar el contenido del archivo\n",
        "with open(yaml_file_path, 'r') as file:\n",
        "    yaml_content = file.read()\n",
        "    print(\"Contenido del archivo techos.yaml:\")\n",
        "    print(yaml_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_516v2FlxEOd",
        "outputId": "16a34006-53cd-4c34-f6f5-26cd9ab652b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenido del archivo techos.yaml:\n",
            "train: 'https://drive.google.com/file/d/1-qAtl8CCD8orRNPtacpsFJVVwfZSNvvW/view?usp=drive_link' # Ruta a la carpeta de entrenamiento\n",
            "val: 'https://drive.google.com/file/d/144a71FiLKrVJcLwMn_IoHz0CYqNoUF6N/view?usp=drive_link'   # Ruta a la carpeta de validaci√≥n\n",
            "\n",
            "nc: 3 # N√∫mero de clases\n",
            "names: ['asbesto', 'laton', 'teja_asfaltica'] # Nombres de las clases\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7biSGUh_zoov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Paso 1: Subir el archivo techos.yaml desde tu PC\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verificar que el archivo se haya subido correctamente\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"Archivo subido: {filename}\")\n",
        "\n",
        "# Paso 2: Mover el archivo a la carpeta /content/prueba\n",
        "temp_yaml_path = '/content/techos.yaml'\n",
        "destination_yaml_path = '/content/prueba/techos.yaml'\n",
        "\n",
        "# Crear la carpeta prueba si no existe\n",
        "os.makedirs('/content/prueba', exist_ok=True)\n",
        "\n",
        "# Mover el archivo a la carpeta destino\n",
        "shutil.move(temp_yaml_path, destination_yaml_path)\n",
        "\n",
        "print(f\"Archivo techos.yaml movido a: {destination_yaml_path}\")\n",
        "\n",
        "# Paso 3: Verificar el contenido del archivo\n",
        "with open(destination_yaml_path, 'r') as file:\n",
        "    yaml_content = file.read()\n",
        "    print(\"Contenido del archivo techos.yaml:\")\n",
        "    print(yaml_content)\n",
        "\n",
        "# Paso 4: Actualizar el archivo YAML si es necesario\n",
        "yaml_content = \"\"\"train: /content/prueba/train/images\n",
        "val: /content/prueba/valid/images\n",
        "test: /content/prueba/test/images\n",
        "\n",
        "nc: 3  # N√∫mero de clases\n",
        "names: ['techo_asbesto', 'techo_metal', 'techo_otro']  # Nombres de las clases\n",
        "\"\"\"\n",
        "\n",
        "with open(destination_yaml_path, 'w') as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "print(\"Archivo techos.yaml actualizado correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "collapsed": true,
        "id": "1dvFVHKOzo7Y",
        "outputId": "32c5958e-7645-4a20-a3a6-d01d00f819b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bfb7314c-ae37-45bb-b636-74bd1085288e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bfb7314c-ae37-45bb-b636-74bd1085288e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving techos.yaml to techos.yaml\n",
            "Archivo subido: techos.yaml\n",
            "Archivo techos.yaml movido a: /content/prueba/techos.yaml\n",
            "Contenido del archivo techos.yaml:\n",
            "train: /content/prueba/train/images\n",
            "val: /content/prueba/valid/images\n",
            "test: /content/prueba/test/images\n",
            "\n",
            "nc: 3\n",
            "names: ['techo_Asbesto', 'techo_Zinc', 'techo_asfaltica']\n",
            "Archivo techos.yaml actualizado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 7 : Instalar dependencias\n",
        "**"
      ],
      "metadata": {
        "id": "g0XcW3yQ1HAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bA5f5mW01LA9",
        "outputId": "d3150131-1173-4d3d-9979-2586b7952066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.75)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.75)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1iFIA2RM1O61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Cargar el modelo preentrenado YOLOv8\n",
        "model = YOLO('yolov8n.pt')  # Puedes cambiar 'yolov8n.pt' por otro modelo seg√∫n tus necesidades"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p8fKDLve1PLk",
        "outputId": "1f8f01cd-02de-4371-f10e-6c48e04bb7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 135MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 8: Entrenar el modelo**"
      ],
      "metadata": {
        "id": "2UFuzSCs4483"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo usando el archivo techos.yaml\n",
        "results = model.train(\n",
        "    data='/content/prueba/techos.yaml',  # Ruta al archivo YAML\n",
        "    epochs=10,                          # N√∫mero de √©pocas\n",
        "    imgsz=640,                          # Tama√±o de la imagen\n",
        "    batch=16,                           # Tama√±o del lote\n",
        "    device='cpu'                        # Usa 'cpu' si no tienes GPU, o '0' si tienes GPU\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "collapsed": true,
        "id": "Rk6M8dBx45Ml",
        "outputId": "c9576da0-901c-4ace-e117-aa0b57cf38c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/prueba/techos.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset '/content/prueba/techos.yaml' error ‚ùå \nDataset '/content/prueba/techos.yaml' images not found ‚ö†Ô∏è, missing path '/content/prueba/valid/images'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m             }:\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nNote dataset download directory is '{DATASETS_DIR}'. You can update this in '{SETTINGS_FILE}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset '/content/prueba/techos.yaml' images not found ‚ö†Ô∏è, missing path '/content/prueba/valid/images'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-253311fddc90>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entrenar el modelo usando el archivo techos.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m results = model.train(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/prueba/techos.yaml'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Ruta al archivo YAML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m                          \u001b[0;31m# N√∫mero de √©pocas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m                          \u001b[0;31m# Tama√±o de la imagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/prueba/techos.yaml' error ‚ùå \nDataset '/content/prueba/techos.yaml' images not found ‚ö†Ô∏è, missing path '/content/prueba/valid/images'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8QBRlj7M7wEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo techos.yaml\n",
        "yaml_file_path = '/content/prueba/techos.yaml'\n",
        "\n",
        "# Nuevo contenido para el archivo YAML con las rutas actualizadas\n",
        "yaml_content = \"\"\"train: /content/prueba/train/train/images\n",
        "val: /content/prueba/valid/valid/images\n",
        "test: /content/prueba/test/test/images\n",
        "\n",
        "nc: 3  # N√∫mero de clases\n",
        "names: ['techo_asbesto', 'techo_metal', 'techo_otro']  # Nombres de las clases\n",
        "\"\"\"\n",
        "\n",
        "# Sobrescribir el archivo techos.yaml con el contenido correcto\n",
        "with open(yaml_file_path, 'w') as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "print(\"Archivo techos.yaml actualizado correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6nvwpx7e7weQ",
        "outputId": "4c1139b1-aa2e-433d-e5ba-be2ae4fa2562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo techos.yaml actualizado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h9yTUoKM7zmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la estructura de carpetas\n",
        "!ls /content/prueba/train/train\n",
        "!ls /content/prueba/valid/valid\n",
        "!ls /content/prueba/test/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yiFdkY3O7z2I",
        "outputId": "888f6353-b17d-4d26-dc46-361da05def7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images\tlabels\n",
            "images\tlabels\n",
            "images\tlabels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 9: UTILIZAR EL MODELO PARA 10 EPOCAS Y VER SU PORCENTAJE DE EFECTIVIDAD**"
      ],
      "metadata": {
        "id": "7E7EP8PC74CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Paso 1: Cargar el modelo preentrenado\n",
        "model = YOLO('yolov8n.pt')  # Puedes cambiar 'yolov8n.pt' por otro modelo seg√∫n tus necesidades\n",
        "\n",
        "# Paso 2: Entrenar el modelo usando el archivo techos.yaml actualizado\n",
        "results = model.train(\n",
        "    data='/content/prueba/techos.yaml',  # Ruta al archivo YAML actualizado\n",
        "    epochs=10,                          # N√∫mero de √©pocas\n",
        "    imgsz=640,                          # Tama√±o de la imagen\n",
        "    batch=16,                           # Tama√±o del lote\n",
        "    device='cpu'                        # Usa 'cpu' si no tienes GPU, o '0' si tienes GPU\n",
        ")\n",
        "\n",
        "# Paso 3: Evaluar el modelo\n",
        "metrics = model.val()\n",
        "print(metrics)\n",
        "\n",
        "# Paso 4: Exportar el modelo (opcional)\n",
        "model.export(format='onnx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9100
        },
        "id": "xYfP16iL74Sg",
        "outputId": "3c83bfe5-5e34-4891-b5c5-9257fd538971"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.75 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/prueba/techos.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 88.5MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/prueba/train/train/labels... 462 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 462/462 [00:00<00:00, 1917.57it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/prueba/train/train/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.4' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/prueba/valid/valid/labels... 45 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:00<00:00, 2553.66it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/prueba/valid/valid/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10         0G      1.379      3.185      1.993         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:13<00:00,  8.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:10<00:00,  5.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48     0.0283      0.875      0.508      0.159\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/10         0G      1.232      2.352      1.852         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:08<00:00,  8.56s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.912      0.645      0.792      0.366\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/10         0G      1.279      2.093      1.864         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:04<00:00,  8.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.774      0.708      0.766      0.356\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/10         0G      1.225      1.866      1.825         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:05<00:00,  8.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.52s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.666      0.604      0.642      0.224\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/10         0G       1.22      1.678      1.816         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:05<00:00,  8.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.77s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.751       0.75      0.813      0.374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/10         0G      1.183      1.536      1.735         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:06<00:00,  8.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.55s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.762      0.667      0.734        0.4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/10         0G       1.11      1.396      1.662         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:05<00:00,  8.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.884      0.854      0.918      0.462\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/10         0G      1.075      1.289      1.604         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:04<00:00,  8.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48      0.889      0.854      0.875      0.548\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/10         0G     0.9923      1.202      1.532         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:05<00:00,  8.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         45         48        0.9      0.937      0.921      0.536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10         0G      0.956      1.123      1.521         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:07<00:00,  8.54s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         45         48      0.931      0.917      0.938      0.525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.714 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.75 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         45         48       0.88      0.854      0.874      0.547\n",
            "         techo_asbesto         45         48       0.88      0.854      0.874      0.547\n",
            "Speed: 2.9ms preprocess, 161.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Ultralytics 8.3.75 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/prueba/valid/valid/labels.cache... 45 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:07<00:00,  2.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         45         48       0.88      0.854      0.874      0.547\n",
            "         techo_asbesto         45         48       0.88      0.854      0.874      0.547\n",
            "Speed: 2.6ms preprocess, 147.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7cda2033ae10>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
            "            0.95455,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,\n",
            "               0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,        0.92,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,\n",
            "            0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.91429,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
            "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,\n",
            "             0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,\n",
            "             0.8913,      0.8913,      0.8913,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,\n",
            "            0.85714,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.81132,     0.58667,     0.58667,\n",
            "            0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,     0.58667,         0.5,         0.5,         0.5,         0.5,\n",
            "                0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,\n",
            "               0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,        0.46,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,\n",
            "           0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,    0.082312,   0.0079293,   0.0075328,   0.0071363,   0.0067399,   0.0063434,    0.005947,   0.0055505,    0.005154,   0.0047576,   0.0043611,\n",
            "          0.0039646,   0.0035682,   0.0031717,   0.0027752,   0.0023788,   0.0019823,   0.0015859,   0.0011894,  0.00079293,  0.00039646,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016365,    0.016365,    0.025991,     0.11529,     0.16667,      0.2159,     0.25801,     0.28851,     0.30825,     0.33214,     0.34678,     0.36862,     0.38963,     0.40674,     0.43024,     0.44901,     0.46754,     0.47403,     0.49053,     0.50279,     0.51602,     0.53141,     0.53691,\n",
            "            0.54197,     0.54361,     0.55458,     0.55671,     0.57438,     0.58058,     0.58729,     0.59045,     0.59211,     0.59745,     0.59994,     0.60319,     0.60637,     0.60857,     0.61021,     0.61157,     0.61294,     0.61572,     0.61822,     0.61982,     0.62141,     0.61676,     0.61248,\n",
            "             0.6137,     0.61491,     0.61612,     0.62748,     0.63781,     0.64251,     0.64999,     0.64694,     0.65203,     0.65279,     0.65355,     0.65431,     0.65507,     0.65583,     0.65658,     0.65958,     0.66291,     0.66602,     0.66939,     0.67244,     0.67466,     0.67687,      0.6776,\n",
            "            0.67828,     0.67897,     0.67965,     0.68034,     0.68102,     0.68171,     0.68272,     0.68445,     0.68618,     0.68777,     0.68897,     0.69017,     0.69136,     0.69255,     0.69909,     0.70395,     0.70944,     0.70499,     0.70547,     0.70594,     0.70641,     0.70688,     0.70736,\n",
            "            0.70783,      0.7083,     0.70877,     0.70924,     0.70971,     0.71018,     0.71065,     0.71217,     0.71394,     0.71569,     0.71872,     0.72286,     0.72413,      0.7254,     0.72667,     0.72794,     0.72996,     0.73369,     0.73527,     0.73563,     0.73598,     0.73634,      0.7367,\n",
            "            0.73705,     0.73741,     0.73777,     0.73812,     0.73848,     0.73883,     0.73919,     0.73954,      0.7399,     0.74025,     0.74061,     0.74096,     0.74131,     0.74164,     0.74196,     0.74228,      0.7426,     0.74292,     0.74324,     0.74356,     0.74387,     0.74419,     0.74451,\n",
            "            0.74483,     0.74515,     0.74546,     0.74578,      0.7461,     0.74642,     0.74673,     0.74705,     0.74737,     0.74768,     0.74838,     0.74939,     0.75041,     0.75141,     0.75242,     0.75342,     0.75459,     0.75955,      0.7621,      0.7636,     0.76509,     0.76658,     0.76795,\n",
            "            0.76862,     0.76929,     0.76996,     0.77062,     0.77129,     0.77195,     0.77262,     0.77328,     0.77394,     0.77461,     0.77502,     0.77536,      0.7757,     0.77603,     0.77637,      0.7767,     0.77703,     0.77737,      0.7777,     0.77804,     0.77837,      0.7787,     0.77904,\n",
            "            0.77937,      0.7797,     0.78004,     0.78037,      0.7807,     0.78103,     0.78136,     0.78169,     0.78215,     0.78268,     0.78321,     0.78374,     0.78427,      0.7848,     0.78533,     0.78586,     0.78639,     0.78691,     0.78744,     0.78796,     0.78849,     0.78902,     0.78963,\n",
            "            0.79025,     0.79086,     0.79148,     0.79209,      0.7927,     0.79331,     0.79392,     0.79453,     0.79514,     0.79575,     0.79645,     0.79799,     0.79951,     0.80104,     0.80256,     0.80384,     0.80432,     0.80479,     0.80526,     0.80574,     0.80621,     0.80668,     0.80715,\n",
            "            0.80762,     0.80809,     0.80856,     0.80903,      0.8095,     0.80997,     0.81044,      0.8109,     0.81189,     0.81723,      0.8205,      0.8227,     0.82489,     0.82695,     0.82738,     0.82781,     0.82824,     0.82867,     0.82909,     0.82952,     0.82995,     0.83037,      0.8308,\n",
            "            0.83123,     0.83165,     0.83208,      0.8325,     0.83292,     0.83335,     0.83377,     0.83419,     0.83462,      0.8354,     0.83755,     0.83969,     0.84183,      0.8435,     0.84446,     0.84541,     0.84636,     0.84731,     0.84826,     0.84921,     0.85015,     0.85109,     0.85121,\n",
            "            0.85074,     0.85027,      0.8498,     0.84932,     0.84885,     0.84838,     0.84791,     0.84743,     0.84696,     0.84649,     0.84601,     0.84554,     0.84506,     0.84459,     0.84411,     0.84364,     0.84316,     0.84269,     0.84221,     0.84173,     0.84126,     0.84078,      0.8403,\n",
            "            0.84015,     0.84055,     0.84096,     0.84136,     0.84177,     0.84217,     0.84258,     0.84298,     0.84338,     0.84379,     0.84419,     0.84459,     0.84499,      0.8454,      0.8458,      0.8462,      0.8466,       0.847,      0.8474,      0.8478,      0.8482,     0.84861,     0.84905,\n",
            "            0.84949,     0.84994,     0.85038,     0.85082,     0.85126,      0.8517,     0.85215,     0.85259,     0.85303,     0.85347,      0.8539,     0.85434,     0.85478,     0.85522,     0.85566,     0.85609,     0.85653,     0.85697,     0.85744,     0.85793,     0.85843,     0.85892,     0.85941,\n",
            "            0.85991,      0.8604,     0.86089,     0.86138,     0.86187,     0.86236,     0.86285,     0.86334,     0.86383,     0.86432,      0.8648,     0.86529,     0.86578,      0.8635,     0.85922,     0.85491,      0.8544,     0.85468,     0.85496,     0.85523,     0.85551,     0.85579,     0.85607,\n",
            "            0.85635,     0.85663,      0.8569,     0.85718,     0.85746,     0.85773,     0.85801,     0.85829,     0.85857,     0.85884,     0.85912,     0.85939,     0.85967,     0.85995,     0.86022,      0.8605,     0.86077,     0.86105,     0.86132,      0.8616,     0.86187,     0.86214,     0.86242,\n",
            "            0.86269,     0.86297,     0.86321,     0.86339,     0.86357,     0.86375,     0.86392,      0.8641,     0.86428,     0.86446,     0.86464,     0.86481,     0.86499,     0.86517,     0.86535,     0.86552,      0.8657,     0.86588,     0.86606,     0.86623,     0.86641,     0.86659,     0.86676,\n",
            "            0.86694,     0.86712,     0.86729,     0.86747,     0.86765,     0.86782,       0.868,     0.86818,     0.86835,     0.86853,     0.86871,     0.86888,     0.86906,     0.86923,     0.86941,     0.86959,     0.86976,     0.86994,     0.87011,     0.87029,     0.87046,     0.87064,     0.87081,\n",
            "            0.87099,     0.87116,     0.87134,     0.87151,     0.87169,     0.87186,     0.87204,     0.87221,     0.87217,     0.87154,     0.87092,     0.87029,     0.86966,     0.86903,      0.8684,     0.86777,     0.86713,      0.8665,     0.86587,     0.86524,      0.8646,     0.86397,     0.86333,\n",
            "             0.8627,     0.86206,     0.86142,     0.86079,     0.85253,     0.84805,     0.84829,     0.84853,     0.84877,     0.84901,     0.84925,     0.84949,     0.84973,     0.84997,     0.85021,     0.85045,     0.85069,     0.85093,     0.85116,      0.8514,     0.85164,     0.85188,     0.85212,\n",
            "            0.85235,     0.85259,     0.85283,     0.85307,      0.8533,     0.85354,     0.85378,     0.85401,     0.85425,     0.85449,     0.85472,     0.85496,      0.8552,     0.85543,     0.85567,      0.8559,     0.85614,     0.85637,     0.85661,     0.85684,     0.85708,     0.84356,      0.8417,\n",
            "            0.83983,     0.83796,     0.83608,      0.8342,     0.83231,     0.83119,     0.83071,     0.83022,     0.82973,     0.82924,     0.82875,     0.82827,     0.82778,     0.82729,      0.8268,     0.82631,     0.82582,     0.82533,     0.82484,     0.82434,     0.82385,     0.82336,     0.82287,\n",
            "            0.82238,     0.82188,     0.82139,      0.8209,      0.8204,     0.81991,     0.81941,     0.81892,     0.81842,     0.81637,     0.81285,      0.8093,     0.80574,     0.80331,     0.80143,     0.79954,     0.79764,     0.79574,     0.79383,     0.79192,     0.79026,     0.78904,     0.78781,\n",
            "            0.78659,     0.78536,     0.78413,      0.7829,     0.78167,     0.78043,     0.77919,     0.77795,     0.77671,      0.7758,     0.77497,     0.77414,     0.77331,     0.77248,     0.77164,     0.77081,     0.76997,     0.76914,      0.7683,     0.76746,     0.76662,     0.76578,     0.76494,\n",
            "             0.7641,     0.76326,     0.76241,     0.76477,     0.77098,     0.76995,     0.76892,     0.76789,     0.76686,     0.76582,     0.76479,     0.76375,     0.76272,     0.76168,     0.76064,     0.75959,     0.75855,      0.7575,     0.75646,     0.75384,     0.75038,      0.7469,     0.74341,\n",
            "            0.74066,     0.74031,     0.73996,      0.7396,     0.73925,      0.7389,     0.73855,      0.7382,     0.73785,      0.7375,     0.73714,     0.73679,     0.73644,     0.73609,     0.73573,     0.73538,     0.73503,     0.73468,     0.73432,     0.73397,     0.73361,     0.73326,     0.73291,\n",
            "            0.73255,      0.7322,     0.73184,     0.73149,     0.73113,     0.73078,     0.73042,     0.73007,     0.72971,     0.72936,       0.729,     0.72864,     0.72829,     0.72793,     0.72758,     0.72722,     0.72686,      0.7265,     0.72615,     0.72579,     0.72543,     0.72507,     0.72458,\n",
            "            0.72404,     0.72351,     0.72298,     0.72244,     0.72191,     0.72137,     0.72083,      0.7203,     0.71976,     0.71923,     0.71869,     0.71815,     0.71761,     0.71707,     0.71654,       0.716,     0.71546,     0.71492,     0.71438,     0.71384,     0.71329,     0.71275,     0.71221,\n",
            "            0.71167,     0.71113,     0.71058,     0.71004,      0.7095,     0.70895,     0.70797,      0.7069,     0.70582,     0.70475,     0.70367,      0.7026,     0.70152,     0.70044,     0.69936,     0.69827,     0.69719,      0.6961,     0.69501,     0.69392,     0.69283,     0.69056,      0.6872,\n",
            "            0.68382,     0.68042,     0.67702,     0.67446,     0.67276,     0.67105,     0.66933,     0.66761,     0.66589,     0.66417,     0.66244,      0.6607,     0.65897,     0.65775,     0.65736,     0.65697,     0.65659,      0.6562,     0.65582,     0.65543,     0.65504,     0.65466,     0.65427,\n",
            "            0.65388,     0.65349,     0.65311,     0.65272,     0.65233,     0.65194,     0.65155,     0.65116,     0.65077,     0.65039,        0.65,     0.64961,     0.64922,     0.64883,     0.64844,     0.64805,     0.64766,     0.64727,     0.64688,     0.64648,     0.64609,      0.6457,     0.64531,\n",
            "            0.64492,     0.64453,     0.64413,     0.64374,     0.64335,     0.64296,     0.64256,     0.64217,     0.64178,     0.64138,     0.64099,      0.6406,      0.6402,     0.63908,     0.63719,     0.63529,     0.63338,     0.63148,     0.62957,     0.62765,     0.62573,      0.6238,     0.62188,\n",
            "            0.62205,     0.62254,     0.62303,     0.62352,       0.624,     0.62449,     0.62497,     0.62545,     0.62593,     0.62641,     0.62689,     0.62737,     0.62784,     0.62832,     0.62879,     0.62926,     0.62973,     0.62726,     0.59389,     0.59741,     0.58898,     0.58045,     0.57679,\n",
            "            0.57359,     0.57037,     0.56714,     0.56389,     0.56063,     0.55831,     0.55715,     0.55599,     0.55482,     0.55366,     0.55249,     0.55133,     0.55016,     0.54898,     0.54781,     0.54664,     0.54546,     0.54428,      0.5431,     0.54192,     0.54074,     0.53955,     0.53836,\n",
            "            0.53068,     0.50879,         0.5,     0.49108,     0.48181,     0.47244,     0.44909,     0.41898,     0.41603,     0.41308,     0.41012,     0.40715,     0.40416,     0.40117,     0.39817,     0.39516,     0.39158,     0.38726,     0.38292,     0.37857,     0.37419,     0.36978,      0.3672,\n",
            "            0.36895,     0.37063,     0.37225,     0.37001,     0.36522,      0.3604,     0.35555,     0.35068,     0.34577,     0.34105,     0.33635,     0.33163,     0.32688,      0.3221,      0.3173,     0.31334,     0.30977,     0.30619,     0.30259,     0.29898,     0.29535,      0.2917,     0.28804,\n",
            "            0.28443,     0.28091,     0.27738,     0.27384,     0.27028,     0.26671,     0.26312,     0.25952,      0.2559,     0.25319,     0.25101,     0.24884,     0.24665,     0.24447,     0.24227,     0.24007,     0.23787,     0.23566,     0.23344,     0.23122,     0.22899,     0.22676,     0.22452,\n",
            "            0.22228,     0.21604,     0.20967,     0.20325,     0.19678,     0.19027,     0.16753,     0.15277,      0.1507,     0.14863,     0.14655,     0.14447,     0.14238,     0.14029,     0.13819,     0.13609,     0.13398,     0.13187,     0.12975,     0.12763,     0.12551,     0.12338,     0.12124,\n",
            "             0.1191,     0.11693,     0.11471,     0.11249,     0.11026,     0.10802,     0.10578,     0.10354,     0.10129,    0.099029,    0.096767,    0.094499,    0.092226,    0.089948,    0.087664,    0.085375,     0.08308,     0.08078,    0.075074,    0.067576,    0.060019,    0.052404,    0.044728,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0082514,   0.0082514,     0.01317,    0.061249,    0.091273,     0.12165,     0.14907,     0.16982,     0.18366,     0.20088,     0.21169,      0.2282,     0.24453,     0.25815,     0.27738,     0.29319,     0.30919,      0.3149,     0.32963,     0.34079,     0.35307,     0.36763,     0.37292,\n",
            "            0.37782,     0.37941,     0.39019,      0.3923,     0.41008,     0.41643,     0.42337,     0.42666,      0.4284,     0.43401,     0.43664,     0.44009,      0.4435,     0.44585,     0.44761,     0.44908,     0.45055,     0.45356,     0.45628,     0.45803,     0.45977,     0.45717,     0.45481,\n",
            "            0.45615,     0.45749,     0.45883,     0.47154,     0.48331,     0.48873,     0.49744,     0.49986,     0.50597,     0.50688,      0.5078,     0.50872,     0.50963,     0.51055,     0.51146,     0.51511,     0.51918,     0.52301,     0.52717,     0.53097,     0.53375,     0.53652,     0.53743,\n",
            "             0.5383,     0.53916,     0.54003,     0.54089,     0.54176,     0.54262,     0.54391,     0.54611,     0.54831,     0.55035,     0.55189,     0.55342,     0.55496,     0.55649,     0.56498,     0.57136,     0.57863,     0.58118,     0.58182,     0.58247,     0.58311,     0.58376,      0.5844,\n",
            "            0.58505,     0.58569,     0.58634,     0.58698,     0.58763,     0.58827,     0.58892,       0.591,     0.59344,     0.59587,     0.60008,     0.60587,     0.60766,     0.60946,     0.61125,     0.61304,     0.61592,     0.62125,     0.62352,     0.62403,     0.62454,     0.62506,     0.62557,\n",
            "            0.62609,      0.6266,     0.62711,     0.62763,     0.62814,     0.62866,     0.62917,     0.62969,      0.6302,     0.63071,     0.63123,     0.63174,     0.63226,     0.63273,      0.6332,     0.63366,     0.63413,     0.63459,     0.63506,     0.63553,     0.63599,     0.63646,     0.63692,\n",
            "            0.63739,     0.63785,     0.63832,     0.63879,     0.63925,     0.63972,     0.64018,     0.64065,     0.64112,     0.64158,     0.64261,     0.64411,      0.6456,     0.64709,     0.64859,     0.65008,     0.65182,     0.65925,     0.66311,     0.66538,     0.66766,     0.66993,     0.67202,\n",
            "            0.67305,     0.67407,      0.6751,     0.67612,     0.67715,     0.67817,      0.6792,     0.68023,     0.68125,     0.68228,     0.68293,     0.68345,     0.68397,     0.68449,     0.68501,     0.68553,     0.68606,     0.68658,      0.6871,     0.68762,     0.68814,     0.68866,     0.68918,\n",
            "             0.6897,     0.69023,     0.69075,     0.69127,     0.69179,     0.69231,     0.69283,     0.69335,     0.69407,     0.69491,     0.69575,     0.69658,     0.69742,     0.69826,      0.6991,     0.69993,     0.70077,     0.70161,     0.70244,     0.70328,     0.70412,     0.70496,     0.70594,\n",
            "            0.70693,     0.70791,      0.7089,     0.70988,     0.71086,     0.71185,     0.71283,     0.71382,      0.7148,     0.71578,     0.71692,     0.71941,      0.7219,     0.72438,     0.72687,     0.72898,     0.72976,     0.73054,     0.73132,      0.7321,     0.73288,     0.73366,     0.73444,\n",
            "            0.73522,       0.736,     0.73678,     0.73756,     0.73834,     0.73912,      0.7399,     0.74068,     0.74234,     0.75131,     0.75685,     0.76061,     0.76436,     0.76791,     0.76865,     0.76939,     0.77013,     0.77087,     0.77161,     0.77235,     0.77309,     0.77383,     0.77457,\n",
            "            0.77531,     0.77605,     0.77679,     0.77753,     0.77827,     0.77901,     0.77975,     0.78049,     0.78123,      0.7826,     0.78639,     0.79017,     0.79396,     0.79695,     0.79866,     0.80036,     0.80207,     0.80378,     0.80549,     0.80719,      0.8089,     0.81061,     0.81123,\n",
            "            0.81108,     0.81093,     0.81078,     0.81063,     0.81048,     0.81033,     0.81018,     0.81003,     0.80989,     0.80974,     0.80959,     0.80944,     0.80929,     0.80914,     0.80899,     0.80884,     0.80869,     0.80854,     0.80839,     0.80824,     0.80809,     0.80794,     0.80779,\n",
            "            0.80797,     0.80872,     0.80947,     0.81022,     0.81097,     0.81172,     0.81247,     0.81322,     0.81397,     0.81472,     0.81548,     0.81623,     0.81698,     0.81773,     0.81848,     0.81923,     0.81998,     0.82073,     0.82148,     0.82223,     0.82299,     0.82376,      0.8246,\n",
            "            0.82543,     0.82627,     0.82711,     0.82794,     0.82878,     0.82962,     0.83045,     0.83129,     0.83213,     0.83297,      0.8338,     0.83464,     0.83548,     0.83631,     0.83715,     0.83799,     0.83882,     0.83966,     0.84056,     0.84152,     0.84247,     0.84342,     0.84437,\n",
            "            0.84532,     0.84628,     0.84723,     0.84818,     0.84913,     0.85008,     0.85103,     0.85199,     0.85294,     0.85389,     0.85484,     0.85579,     0.85675,     0.85651,     0.85543,     0.85435,     0.85463,     0.85519,     0.85575,      0.8563,     0.85686,     0.85742,     0.85798,\n",
            "            0.85854,      0.8591,     0.85966,     0.86022,     0.86077,     0.86133,     0.86189,     0.86245,     0.86301,     0.86357,     0.86413,     0.86469,     0.86524,      0.8658,     0.86636,     0.86692,     0.86748,     0.86804,      0.8686,     0.86916,     0.86971,     0.87027,     0.87083,\n",
            "            0.87139,     0.87195,     0.87245,     0.87281,     0.87318,     0.87354,     0.87391,     0.87427,     0.87464,       0.875,     0.87537,     0.87573,     0.87609,     0.87646,     0.87682,     0.87719,     0.87755,     0.87792,     0.87828,     0.87865,     0.87901,     0.87937,     0.87974,\n",
            "             0.8801,     0.88047,     0.88083,      0.8812,     0.88156,     0.88193,     0.88229,     0.88265,     0.88302,     0.88338,     0.88375,     0.88411,     0.88448,     0.88484,     0.88521,     0.88557,     0.88593,      0.8863,     0.88666,     0.88703,     0.88739,     0.88776,     0.88812,\n",
            "            0.88849,     0.88885,     0.88922,     0.88958,     0.88994,     0.89031,     0.89067,     0.89104,     0.89127,     0.89114,     0.89102,     0.89089,     0.89077,     0.89064,     0.89051,     0.89039,     0.89026,     0.89014,     0.89001,     0.88988,     0.88976,     0.88963,     0.88951,\n",
            "            0.88938,     0.88925,     0.88913,       0.889,     0.88732,     0.88686,     0.88738,     0.88791,     0.88843,     0.88896,     0.88948,     0.89001,     0.89054,     0.89106,     0.89159,     0.89211,     0.89264,     0.89316,     0.89369,     0.89422,     0.89474,     0.89527,     0.89579,\n",
            "            0.89632,     0.89685,     0.89737,      0.8979,     0.89842,     0.89895,     0.89947,         0.9,     0.90053,     0.90105,     0.90158,      0.9021,     0.90263,     0.90315,     0.90368,     0.90421,     0.90473,     0.90526,     0.90578,     0.90631,     0.90683,      0.9046,     0.90427,\n",
            "            0.90393,      0.9036,     0.90326,     0.90292,     0.90259,     0.90239,      0.9023,     0.90221,     0.90212,     0.90203,     0.90194,     0.90185,     0.90176,     0.90167,     0.90158,     0.90149,      0.9014,     0.90131,     0.90122,     0.90113,     0.90104,     0.90095,     0.90086,\n",
            "            0.90077,     0.90068,     0.90059,     0.90049,      0.9004,     0.90031,     0.90022,     0.90013,     0.90004,     0.89966,     0.89899,     0.89832,     0.89765,     0.89718,     0.89682,     0.89645,     0.89608,     0.89571,     0.89534,     0.89497,     0.89465,      0.8944,     0.89416,\n",
            "            0.89391,     0.89366,     0.89342,     0.89317,     0.89292,     0.89268,     0.89243,     0.89219,     0.89194,     0.89175,     0.89158,     0.89141,     0.89124,     0.89106,     0.89089,     0.89072,     0.89055,     0.89037,      0.8902,     0.89003,     0.88986,     0.88968,     0.88951,\n",
            "            0.88934,     0.88916,     0.88899,     0.89673,     0.91427,     0.91409,     0.91392,     0.91374,     0.91357,     0.91339,     0.91322,     0.91305,     0.91287,      0.9127,     0.91252,     0.91235,     0.91217,       0.912,     0.91182,     0.91137,     0.91076,     0.91016,     0.90955,\n",
            "            0.90908,     0.90901,     0.90895,     0.90888,     0.90882,     0.90876,     0.90869,     0.90863,     0.90856,      0.9085,     0.90844,     0.90837,     0.90831,     0.90824,     0.90818,     0.90812,     0.90805,     0.90799,     0.90793,     0.90786,      0.9078,     0.90773,     0.90767,\n",
            "            0.90761,     0.90754,     0.90748,     0.90741,     0.90735,     0.90729,     0.90722,     0.90716,     0.90709,     0.90703,     0.90697,      0.9069,     0.90684,     0.90677,     0.90671,     0.90665,     0.90658,     0.90652,     0.90645,     0.90639,     0.90633,     0.90626,     0.90617,\n",
            "            0.90607,     0.90597,     0.90587,     0.90577,     0.90567,     0.90556,     0.90546,     0.90536,     0.90526,     0.90516,     0.90506,     0.90496,     0.90486,     0.90476,     0.90466,     0.90455,     0.90445,     0.90435,     0.90425,     0.90415,     0.90405,     0.90395,     0.90385,\n",
            "            0.90375,     0.90365,     0.90355,     0.90344,     0.90334,     0.90324,     0.90305,     0.90284,     0.90263,     0.90242,     0.90221,       0.902,     0.90179,     0.90158,     0.90136,     0.90115,     0.90094,     0.90073,     0.90052,     0.90031,      0.9001,     0.89964,     0.89895,\n",
            "            0.89827,     0.89758,     0.89689,     0.89637,       0.896,     0.89564,     0.89527,     0.89491,     0.89454,     0.89418,     0.89381,     0.89345,     0.89308,     0.89282,     0.89274,     0.89265,     0.89256,     0.89248,     0.89239,     0.89231,     0.89222,     0.89213,     0.89205,\n",
            "            0.89196,     0.89187,     0.89179,      0.8917,     0.89161,     0.89153,     0.89144,     0.89135,     0.89127,     0.89118,     0.89109,     0.89101,     0.89092,     0.89084,     0.89075,     0.89066,     0.89058,     0.89049,      0.8904,     0.89032,     0.89023,     0.89014,     0.89006,\n",
            "            0.88997,     0.88988,      0.8898,     0.88971,     0.88962,     0.88954,     0.88945,     0.88937,     0.88928,     0.88919,     0.88911,     0.88902,     0.88893,     0.88867,     0.88823,     0.88778,     0.88734,      0.8869,     0.88645,     0.88601,     0.88556,     0.88512,     0.88467,\n",
            "            0.88635,     0.88834,     0.89034,     0.89233,     0.89433,     0.89632,     0.89832,     0.90031,     0.90231,      0.9043,      0.9063,      0.9083,     0.91029,     0.91229,     0.91428,     0.91628,     0.91827,     0.91949,      0.9243,     0.95427,     0.95336,     0.95246,     0.95204,\n",
            "            0.95168,     0.95131,     0.95094,     0.95057,      0.9502,     0.94994,     0.94979,     0.94965,     0.94951,     0.94936,     0.94922,     0.94907,     0.94893,     0.94879,     0.94864,      0.9485,     0.94836,     0.94821,     0.94807,     0.94793,     0.94778,     0.94764,      0.9475,\n",
            "            0.94648,     0.94353,     0.94227,     0.94098,     0.93953,     0.93807,     0.93412,     0.92849,     0.92786,     0.92723,     0.92659,     0.92596,     0.92533,      0.9247,     0.92407,     0.92344,     0.92262,     0.92158,     0.92054,     0.91949,     0.91845,      0.9174,     0.92332,\n",
            "            0.94588,     0.96844,       0.991,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.97917,     0.97917,     0.97917,     0.97917,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,\n",
            "            0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.95833,     0.94751,      0.9375,\n",
            "             0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,\n",
            "            0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.91667,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,\n",
            "            0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89583,     0.89533,\n",
            "            0.89447,     0.89361,     0.89275,     0.89189,     0.89103,     0.89017,     0.88931,     0.88845,     0.88759,     0.88673,     0.88587,     0.88501,     0.88415,     0.88329,     0.88243,     0.88157,     0.88071,     0.87985,     0.87899,     0.87813,     0.87727,     0.87641,     0.87555,\n",
            "              0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,\n",
            "              0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,\n",
            "              0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,       0.875,     0.87059,     0.86304,     0.85548,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,\n",
            "            0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,\n",
            "            0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,\n",
            "            0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,\n",
            "            0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85417,     0.85388,     0.85279,      0.8517,     0.85061,     0.84953,     0.84844,     0.84735,     0.84627,     0.84518,     0.84409,       0.843,     0.84192,     0.84083,     0.83974,     0.83866,\n",
            "            0.83757,     0.83648,     0.83539,     0.83431,     0.82037,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,\n",
            "             0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,      0.8125,     0.79024,     0.78723,\n",
            "            0.78422,     0.78121,      0.7782,     0.77519,     0.77218,     0.77041,     0.76964,     0.76887,      0.7681,     0.76733,     0.76656,     0.76578,     0.76501,     0.76424,     0.76347,      0.7627,     0.76193,     0.76116,     0.76039,     0.75962,     0.75885,     0.75808,     0.75731,\n",
            "            0.75654,     0.75577,       0.755,     0.75423,     0.75346,     0.75269,     0.75192,     0.75114,     0.75037,     0.74721,     0.74177,     0.73633,      0.7309,     0.72723,     0.72438,     0.72153,     0.71869,     0.71584,       0.713,     0.71015,     0.70768,     0.70588,     0.70408,\n",
            "            0.70227,     0.70047,     0.69867,     0.69686,     0.69506,     0.69326,     0.69145,     0.68965,     0.68785,     0.68653,     0.68534,     0.68414,     0.68294,     0.68175,     0.68055,     0.67935,     0.67816,     0.67696,     0.67576,     0.67457,     0.67337,     0.67217,     0.67098,\n",
            "            0.66978,     0.66858,     0.66739,     0.66667,     0.66651,     0.66507,     0.66363,     0.66219,     0.66075,     0.65931,     0.65786,     0.65642,     0.65498,     0.65354,      0.6521,     0.65065,     0.64921,     0.64777,     0.64633,     0.64274,     0.63802,      0.6333,     0.62859,\n",
            "            0.62489,     0.62442,     0.62395,     0.62348,     0.62301,     0.62254,     0.62208,     0.62161,     0.62114,     0.62067,      0.6202,     0.61973,     0.61926,     0.61879,     0.61833,     0.61786,     0.61739,     0.61692,     0.61645,     0.61598,     0.61551,     0.61504,     0.61458,\n",
            "            0.61411,     0.61364,     0.61317,      0.6127,     0.61223,     0.61176,     0.61129,     0.61083,     0.61036,     0.60989,     0.60942,     0.60895,     0.60848,     0.60801,     0.60754,     0.60708,     0.60661,     0.60614,     0.60567,      0.6052,     0.60473,     0.60426,     0.60361,\n",
            "            0.60292,     0.60222,     0.60153,     0.60083,     0.60014,     0.59944,     0.59875,     0.59805,     0.59736,     0.59666,     0.59597,     0.59527,     0.59458,     0.59388,     0.59318,     0.59249,     0.59179,      0.5911,      0.5904,     0.58971,     0.58901,     0.58832,     0.58762,\n",
            "            0.58693,     0.58623,     0.58554,     0.58484,     0.58414,     0.58345,      0.5822,     0.58084,     0.57948,     0.57812,     0.57676,      0.5754,     0.57404,     0.57268,     0.57131,     0.56995,     0.56859,     0.56723,     0.56587,     0.56451,     0.56315,     0.56033,     0.55618,\n",
            "            0.55203,     0.54788,     0.54372,     0.54063,     0.53857,     0.53651,     0.53445,     0.53239,     0.53034,     0.52828,     0.52622,     0.52416,      0.5221,     0.52066,     0.52021,     0.51975,      0.5193,     0.51884,     0.51839,     0.51794,     0.51748,     0.51703,     0.51657,\n",
            "            0.51612,     0.51567,     0.51521,     0.51476,      0.5143,     0.51385,      0.5134,     0.51294,     0.51249,     0.51203,     0.51158,     0.51113,     0.51067,     0.51022,     0.50977,     0.50931,     0.50886,      0.5084,     0.50795,      0.5075,     0.50704,     0.50659,     0.50613,\n",
            "            0.50568,     0.50523,     0.50477,     0.50432,     0.50386,     0.50341,     0.50296,      0.5025,     0.50205,     0.50159,     0.50114,     0.50069,     0.50023,     0.49894,     0.49678,     0.49461,     0.49245,     0.49028,     0.48811,     0.48595,     0.48378,     0.48162,     0.47945,\n",
            "            0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47917,     0.47598,      0.4375,     0.43481,     0.42611,     0.41741,     0.41372,\n",
            "             0.4105,     0.40728,     0.40406,     0.40084,     0.39761,     0.39533,     0.39419,     0.39305,     0.39192,     0.39078,     0.38964,     0.38851,     0.38737,     0.38623,      0.3851,     0.38396,     0.38282,     0.38169,     0.38055,     0.37941,     0.37828,     0.37714,       0.376,\n",
            "             0.3687,     0.34831,     0.34029,     0.33223,     0.32398,     0.31572,      0.2956,     0.27052,     0.26813,     0.26573,     0.26334,     0.26094,     0.25855,     0.25615,     0.25375,     0.25136,     0.24853,     0.24514,     0.24174,     0.23835,     0.23495,     0.23156,     0.22917,\n",
            "            0.22917,     0.22917,     0.22917,       0.227,     0.22341,     0.21981,     0.21622,     0.21262,     0.20902,     0.20558,     0.20218,     0.19877,     0.19537,     0.19197,     0.18856,     0.18578,     0.18327,     0.18077,     0.17827,     0.17576,     0.17326,     0.17075,     0.16825,\n",
            "            0.16579,     0.16341,     0.16102,     0.15864,     0.15626,     0.15387,     0.15149,     0.14911,     0.14672,     0.14494,     0.14352,      0.1421,     0.14068,     0.13925,     0.13783,     0.13641,     0.13499,     0.13357,     0.13214,     0.13072,      0.1293,     0.12788,     0.12646,\n",
            "            0.12503,      0.1211,     0.11711,     0.11312,     0.10913,     0.10514,    0.091423,    0.082704,    0.081492,    0.080281,    0.079069,    0.077858,    0.076647,    0.075435,    0.074224,    0.073012,    0.071801,     0.07059,    0.069378,    0.068167,    0.066955,    0.065744,    0.064533,\n",
            "           0.063321,    0.062097,    0.060847,    0.059596,    0.058346,    0.057095,    0.055845,    0.054595,    0.053344,    0.052094,    0.050843,    0.049593,    0.048342,    0.047092,    0.045841,    0.044591,    0.043341,     0.04209,    0.039001,    0.034969,    0.030938,    0.026907,    0.022876,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: 0.5796969779936172\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.54703,     0.54703,     0.54703])\n",
            "names: {0: 'techo_asbesto', 1: 'techo_metal', 2: 'techo_otro'}\n",
            "plot: True\n",
            "results_dict: {'metrics/precision(B)': 0.8797388944966583, 'metrics/recall(B)': 0.8541666666666666, 'metrics/mAP50(B)': 0.8737351771810378, 'metrics/mAP50-95(B)': 0.5470260669727927, 'fitness': 0.5796969779936172}\n",
            "save_dir: PosixPath('runs/detect/train22')\n",
            "speed: {'preprocess': 2.6142240888980774, 'inference': 147.18957446667545, 'loss': 0.00010273332817531707, 'postprocess': 2.697787177769189}\n",
            "task: 'detect'\n",
            "Ultralytics 8.3.75 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim', 'onnxruntime'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxslim\n",
            "  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim) (24.2)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.1.24)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16.0/16.0 MB 118.4 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 142.9/142.9 kB 318.7 MB/s eta 0:00:00\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.3/13.3 MB 225.2 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 kB 221.9 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 kB 281.4 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx, humanfriendly, onnxslim, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1 onnxslim-0.1.48\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 6.7s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim', 'onnxruntime']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 8.5s, saved as 'runs/detect/train2/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "Export complete (8.9s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train2/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train2/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train2/weights/best.onnx imgsz=640 data=/content/prueba/techos.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'runs/detect/train2/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}